{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils\\split_dataset.py \\\n",
    "    --input_file \"dataset/merged_dataset.json\" \\\n",
    "    --output_dir \"dataset\" \\\n",
    "    --include_val \\\n",
    "    --train_ratio 0.8 \\\n",
    "    --val_ratio 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Get QA code from the AraBERT repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir arabert-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'arabert'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 dir(s) moved.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aub-mind/arabert\n",
    "!move arabert arabert-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n",
      "        1 file(s) copied.\n",
      "        1 file(s) copied.\n",
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "!copy arabert-model\\arabert\\examples\\question-answering\\utils_qa.py arabert-model\\utils_qa.py\n",
    "!copy arabert-model\\arabert\\examples\\question-answering\\trainer_qa.py arabert-model\\trainer_qa.py\n",
    "!copy arabert-model\\arabert\\examples\\question-answering\\run_qa.py arabert-model\\run_qa.py\n",
    "!copy arabert-model\\arabert\\examples\\question-answering\\squad_preprocessing.py arabert-model\\squad_preprocessing.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could Not Find d:\\New folder\\AraBERT-qa-model\\dataset\\pre\\*-pre.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\\pre\n",
    "!del /q dataset\\pre\\*-pre.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"aubmindlab/bert-base-arabertv02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15230 [00:00<?, ?it/s]\n",
      "  0%|          | 33/15230 [00:00<00:46, 325.73it/s]\n",
      "  1%|          | 86/15230 [00:00<00:34, 440.01it/s]\n",
      "  1%|          | 138/15230 [00:00<00:31, 474.63it/s]\n",
      "  1%|          | 187/15230 [00:00<00:31, 478.09it/s]\n",
      "  2%|▏         | 235/15230 [00:00<00:32, 460.26it/s]\n",
      "  2%|▏         | 282/15230 [00:00<00:33, 442.72it/s]\n",
      "  2%|▏         | 335/15230 [00:00<00:31, 468.06it/s]\n",
      "  3%|▎         | 396/15230 [00:00<00:29, 507.86it/s]\n",
      "  3%|▎         | 448/15230 [00:00<00:29, 496.06it/s]\n",
      "  3%|▎         | 503/15230 [00:01<00:28, 511.54it/s]\n",
      "  4%|▍         | 575/15230 [00:01<00:25, 572.91it/s]\n",
      "  4%|▍         | 633/15230 [00:01<00:26, 560.25it/s]\n",
      "  5%|▍         | 703/15230 [00:01<00:24, 597.76it/s]\n",
      "  5%|▌         | 764/15230 [00:01<00:24, 590.76it/s]\n",
      "  5%|▌         | 827/15230 [00:01<00:23, 600.48it/s]\n",
      "  6%|▌         | 888/15230 [00:01<00:24, 584.92it/s]\n",
      "  6%|▌         | 947/15230 [00:01<00:24, 584.25it/s]\n",
      "  7%|▋         | 1013/15230 [00:01<00:23, 605.43it/s]\n",
      "  7%|▋         | 1074/15230 [00:02<00:25, 552.86it/s]\n",
      "  7%|▋         | 1133/15230 [00:02<00:25, 562.63it/s]\n",
      "  8%|▊         | 1190/15230 [00:02<00:25, 547.30it/s]\n",
      "  8%|▊         | 1246/15230 [00:02<00:25, 547.41it/s]\n",
      "  9%|▊         | 1302/15230 [00:02<00:27, 512.65it/s]\n",
      "  9%|▉         | 1354/15230 [00:02<00:28, 489.01it/s]\n",
      "  9%|▉         | 1404/15230 [00:02<00:29, 460.93it/s]\n",
      " 10%|▉         | 1456/15230 [00:02<00:28, 475.25it/s]\n",
      " 10%|▉         | 1521/15230 [00:02<00:26, 522.86it/s]\n",
      " 10%|█         | 1578/15230 [00:02<00:25, 534.14it/s]\n",
      " 11%|█         | 1639/15230 [00:03<00:24, 555.37it/s]\n",
      " 11%|█         | 1696/15230 [00:03<00:24, 554.30it/s]\n",
      " 12%|█▏        | 1765/15230 [00:03<00:23, 584.74it/s]\n",
      " 12%|█▏        | 1827/15230 [00:03<00:22, 592.69it/s]\n",
      " 12%|█▏        | 1887/15230 [00:03<00:22, 589.08it/s]\n",
      " 13%|█▎        | 1950/15230 [00:03<00:22, 600.52it/s]\n",
      " 13%|█▎        | 2011/15230 [00:03<00:24, 545.96it/s]\n",
      " 14%|█▎        | 2067/15230 [00:03<00:24, 527.53it/s]\n",
      " 14%|█▍        | 2121/15230 [00:03<00:25, 520.87it/s]\n",
      " 14%|█▍        | 2199/15230 [00:04<00:22, 589.73it/s]\n",
      " 15%|█▍        | 2267/15230 [00:04<00:21, 612.18it/s]\n",
      " 15%|█▌        | 2329/15230 [00:04<00:21, 597.51it/s]\n",
      " 16%|█▌        | 2391/15230 [00:04<00:21, 601.63it/s]\n",
      " 16%|█▌        | 2459/15230 [00:04<00:20, 620.13it/s]\n",
      " 17%|█▋        | 2522/15230 [00:04<00:20, 613.47it/s]\n",
      " 17%|█▋        | 2591/15230 [00:04<00:19, 633.58it/s]\n",
      " 17%|█▋        | 2655/15230 [00:04<00:22, 564.69it/s]\n",
      " 18%|█▊        | 2713/15230 [00:04<00:22, 566.04it/s]\n",
      " 18%|█▊        | 2771/15230 [00:05<00:22, 563.26it/s]\n",
      " 19%|█▊        | 2829/15230 [00:05<00:22, 561.14it/s]\n",
      " 19%|█▉        | 2898/15230 [00:05<00:20, 597.25it/s]\n",
      " 19%|█▉        | 2965/15230 [00:05<00:19, 615.99it/s]\n",
      " 20%|█▉        | 3034/15230 [00:05<00:19, 636.62it/s]\n",
      " 20%|██        | 3099/15230 [00:05<00:19, 610.92it/s]\n",
      " 21%|██        | 3163/15230 [00:05<00:19, 616.83it/s]\n",
      " 21%|██        | 3230/15230 [00:05<00:19, 631.58it/s]\n",
      " 22%|██▏       | 3294/15230 [00:05<00:19, 615.52it/s]\n",
      " 22%|██▏       | 3356/15230 [00:05<00:20, 586.59it/s]\n",
      " 22%|██▏       | 3416/15230 [00:06<00:20, 589.24it/s]\n",
      " 23%|██▎       | 3486/15230 [00:06<00:18, 618.48it/s]\n",
      " 23%|██▎       | 3552/15230 [00:06<00:18, 628.14it/s]\n",
      " 24%|██▎       | 3616/15230 [00:06<00:19, 583.49it/s]\n",
      " 24%|██▍       | 3676/15230 [00:06<00:20, 573.28it/s]\n",
      " 25%|██▍       | 3734/15230 [00:06<00:21, 547.30it/s]\n",
      " 25%|██▍       | 3805/15230 [00:06<00:19, 589.87it/s]\n",
      " 25%|██▌       | 3865/15230 [00:06<00:20, 547.73it/s]\n",
      " 26%|██▌       | 3925/15230 [00:06<00:20, 559.91it/s]\n",
      " 26%|██▌       | 3982/15230 [00:07<00:21, 529.84it/s]\n",
      " 27%|██▋       | 4042/15230 [00:07<00:20, 547.00it/s]\n",
      " 27%|██▋       | 4100/15230 [00:07<00:20, 552.61it/s]\n",
      " 27%|██▋       | 4168/15230 [00:07<00:18, 588.26it/s]\n",
      " 28%|██▊       | 4228/15230 [00:07<00:19, 551.54it/s]\n",
      " 28%|██▊       | 4295/15230 [00:07<00:18, 582.29it/s]\n",
      " 29%|██▊       | 4354/15230 [00:07<00:19, 563.37it/s]\n",
      " 29%|██▉       | 4416/15230 [00:07<00:18, 576.88it/s]\n",
      " 29%|██▉       | 4475/15230 [00:07<00:19, 542.65it/s]\n",
      " 30%|██▉       | 4534/15230 [00:08<00:19, 555.39it/s]\n",
      " 30%|███       | 4598/15230 [00:08<00:18, 577.86it/s]\n",
      " 31%|███       | 4657/15230 [00:08<00:18, 556.65it/s]\n",
      " 31%|███       | 4722/15230 [00:08<00:18, 579.92it/s]\n",
      " 31%|███▏      | 4782/15230 [00:08<00:17, 585.16it/s]\n",
      " 32%|███▏      | 4849/15230 [00:08<00:17, 604.88it/s]\n",
      " 32%|███▏      | 4910/15230 [00:08<00:17, 592.92it/s]\n",
      " 33%|███▎      | 4970/15230 [00:08<00:18, 547.37it/s]\n",
      " 33%|███▎      | 5026/15230 [00:08<00:18, 537.18it/s]\n",
      " 33%|███▎      | 5081/15230 [00:09<00:20, 488.46it/s]\n",
      " 34%|███▎      | 5140/15230 [00:09<00:19, 514.78it/s]\n",
      " 34%|███▍      | 5205/15230 [00:09<00:18, 551.36it/s]\n",
      " 35%|███▍      | 5262/15230 [00:09<00:17, 554.56it/s]\n",
      " 35%|███▍      | 5319/15230 [00:09<00:17, 555.30it/s]\n",
      " 35%|███▌      | 5380/15230 [00:09<00:17, 568.98it/s]\n",
      " 36%|███▌      | 5438/15230 [00:09<00:17, 571.75it/s]\n",
      " 36%|███▌      | 5496/15230 [00:09<00:17, 572.38it/s]\n",
      " 37%|███▋      | 5563/15230 [00:09<00:16, 600.14it/s]WARNING:tensorflow:Could not find answer for question 'arabic-1804271180688859213-0' :\n",
      " 'الإسكندر الثالث المقدوني ، المعروف بأسماء عديدة أخرى أبرزها : الإسكندر الأكبر ، و < b data - parsoid = ' { \" dsr \" : [1849 , 1870 , 3 , 3] } ' > الإسكندر الكبير ، و < b data - parsoid = ' { \" dsr \" : [1873 , 1896 , 3 , 3] } ' > الإسكندر المقدوني ، و < b data - parsoid = ' { \" dsr \" : [1899 , 1924 , 3 , 3] } ' > الإسكندر ذو القرنين ( باليونانية : ؛ نقحرة : ) ، هو أحد ملوك مقدونيا الإغريق ، ومن أشهر القادة العسكريين والفاتحين عبر التاريخ . ولد الإسكندر في مدينة يلا قرابة سنة 356 ق . م ، وتتلمذ على يد الفيلسوف والعالم الشهير أرسطو حتى بلغ ربيعه السادس عشر . وبحلول عامه الثلاثين ، كان قد أسس إحدى أكبر وأعظم الإمبراطوريات التي عرفها العالم القديم ، والتي امتدت من سواحل البحر الأيوني غربا وصولا إلى سلسلة جبال الهيمالايا شرقا . يعد أحد أنجح القادة العسكريين في مسيرتهم ، إذ لم يحصل أن هزم في أي معركة خاضها على الإطلاق . [1]' \n",
      "vs.\n",
      " 'Ἀλέξανδρο'\n",
      "orig answer:\n",
      " 'Ἀλέξανδρο'\n",
      "==================\n",
      "\n",
      " 37%|███▋      | 5624/15230 [00:10<00:17, 551.53it/s]\n",
      " 37%|███▋      | 5681/15230 [00:10<00:17, 534.72it/s]\n",
      " 38%|███▊      | 5736/15230 [00:10<00:17, 533.99it/s]\n",
      " 38%|███▊      | 5790/15230 [00:10<00:17, 526.40it/s]\n",
      " 38%|███▊      | 5843/15230 [00:10<00:17, 524.08it/s]\n",
      " 39%|███▊      | 5896/15230 [00:10<00:18, 503.83it/s]\n",
      " 39%|███▉      | 5951/15230 [00:10<00:18, 514.94it/s]\n",
      " 39%|███▉      | 6014/15230 [00:10<00:17, 538.18it/s]\n",
      " 40%|███▉      | 6071/15230 [00:10<00:16, 538.87it/s]\n",
      " 40%|████      | 6126/15230 [00:10<00:17, 513.91it/s]\n",
      " 41%|████      | 6179/15230 [00:11<00:17, 516.56it/s]\n",
      " 41%|████      | 6231/15230 [00:11<00:17, 512.80it/s]\n",
      " 41%|████▏     | 6285/15230 [00:11<00:17, 520.16it/s]\n",
      " 42%|████▏     | 6338/15230 [00:11<00:18, 482.02it/s]\n",
      " 42%|████▏     | 6395/15230 [00:11<00:17, 504.09it/s]\n",
      " 42%|████▏     | 6454/15230 [00:11<00:16, 526.67it/s]\n",
      " 43%|████▎     | 6529/15230 [00:11<00:14, 590.73it/s]\n",
      " 43%|████▎     | 6589/15230 [00:11<00:15, 572.98it/s]\n",
      " 44%|████▎     | 6647/15230 [00:11<00:15, 564.77it/s]\n",
      " 44%|████▍     | 6705/15230 [00:12<00:15, 567.65it/s]\n",
      " 44%|████▍     | 6763/15230 [00:12<00:16, 528.36it/s]\n",
      " 45%|████▍     | 6817/15230 [00:12<00:16, 503.85it/s]\n",
      " 45%|████▌     | 6868/15230 [00:12<00:16, 498.47it/s]\n",
      " 46%|████▌     | 6939/15230 [00:12<00:14, 555.04it/s]\n",
      " 46%|████▌     | 7002/15230 [00:12<00:14, 575.74it/s]\n",
      " 46%|████▋     | 7061/15230 [00:12<00:14, 575.94it/s]\n",
      " 47%|████▋     | 7120/15230 [00:12<00:14, 560.07it/s]\n",
      " 47%|████▋     | 7186/15230 [00:12<00:13, 587.41it/s]\n",
      " 48%|████▊     | 7246/15230 [00:13<00:13, 587.00it/s]\n",
      " 48%|████▊     | 7305/15230 [00:13<00:14, 560.82it/s]\n",
      " 48%|████▊     | 7362/15230 [00:13<00:15, 492.02it/s]\n",
      " 49%|████▉     | 7427/15230 [00:13<00:14, 531.98it/s]\n",
      " 49%|████▉     | 7482/15230 [00:13<00:14, 523.77it/s]\n",
      " 49%|████▉     | 7536/15230 [00:13<00:14, 514.06it/s]\n",
      " 50%|████▉     | 7589/15230 [00:13<00:14, 517.98it/s]\n",
      " 50%|█████     | 7645/15230 [00:13<00:14, 527.87it/s]\n",
      " 51%|█████     | 7708/15230 [00:13<00:13, 555.24it/s]\n",
      " 51%|█████     | 7765/15230 [00:14<00:13, 558.93it/s]\n",
      " 51%|█████▏    | 7826/15230 [00:14<00:12, 573.31it/s]\n",
      " 52%|█████▏    | 7884/15230 [00:14<00:13, 563.19it/s]\n",
      " 52%|█████▏    | 7942/15230 [00:14<00:12, 562.59it/s]\n",
      " 53%|█████▎    | 8010/15230 [00:14<00:12, 594.58it/s]\n",
      " 53%|█████▎    | 8072/15230 [00:14<00:11, 597.94it/s]\n",
      " 53%|█████▎    | 8132/15230 [00:14<00:12, 579.48it/s]\n",
      " 54%|█████▍    | 8198/15230 [00:14<00:11, 600.60it/s]\n",
      " 54%|█████▍    | 8259/15230 [00:14<00:12, 561.37it/s]\n",
      " 55%|█████▍    | 8322/15230 [00:14<00:11, 580.38it/s]\n",
      " 55%|█████▌    | 8387/15230 [00:15<00:11, 597.77it/s]\n",
      " 55%|█████▌    | 8448/15230 [00:15<00:11, 571.18it/s]\n",
      " 56%|█████▌    | 8506/15230 [00:15<00:12, 553.58it/s]\n",
      " 56%|█████▌    | 8562/15230 [00:15<00:12, 541.00it/s]\n",
      " 57%|█████▋    | 8618/15230 [00:15<00:12, 542.60it/s]\n",
      " 57%|█████▋    | 8673/15230 [00:15<00:12, 530.69it/s]\n",
      " 57%|█████▋    | 8727/15230 [00:15<00:13, 472.83it/s]\n",
      " 58%|█████▊    | 8781/15230 [00:15<00:13, 490.22it/s]\n",
      " 58%|█████▊    | 8842/15230 [00:15<00:12, 521.16it/s]\n",
      " 58%|█████▊    | 8909/15230 [00:16<00:11, 562.50it/s]\n",
      " 59%|█████▉    | 8967/15230 [00:16<00:11, 559.04it/s]\n",
      " 59%|█████▉    | 9038/15230 [00:16<00:10, 598.05it/s]\n",
      " 60%|█████▉    | 9099/15230 [00:16<00:10, 564.04it/s]\n",
      " 60%|██████    | 9157/15230 [00:16<00:11, 540.15it/s]\n",
      " 61%|██████    | 9218/15230 [00:16<00:10, 557.37it/s]\n",
      " 61%|██████    | 9279/15230 [00:16<00:10, 568.53it/s]\n",
      " 61%|██████▏   | 9340/15230 [00:16<00:10, 579.76it/s]\n",
      " 62%|██████▏   | 9406/15230 [00:16<00:09, 593.92it/s]\n",
      " 62%|██████▏   | 9467/15230 [00:17<00:09, 596.28it/s]\n",
      " 63%|██████▎   | 9527/15230 [00:17<00:09, 571.99it/s]\n",
      " 63%|██████▎   | 9588/15230 [00:17<00:09, 580.64it/s]\n",
      " 63%|██████▎   | 9647/15230 [00:17<00:09, 574.56it/s]\n",
      " 64%|██████▎   | 9707/15230 [00:17<00:09, 579.67it/s]\n",
      " 64%|██████▍   | 9768/15230 [00:17<00:09, 586.28it/s]\n",
      " 65%|██████▍   | 9827/15230 [00:17<00:09, 577.32it/s]\n",
      " 65%|██████▍   | 9895/15230 [00:17<00:08, 606.64it/s]\n",
      " 65%|██████▌   | 9973/15230 [00:17<00:08, 656.46it/s]\n",
      " 66%|██████▌   | 10042/15230 [00:17<00:07, 661.81it/s]\n",
      " 66%|██████▋   | 10109/15230 [00:18<00:08, 596.83it/s]\n",
      " 67%|██████▋   | 10170/15230 [00:18<00:08, 584.54it/s]\n",
      " 67%|██████▋   | 10230/15230 [00:18<00:08, 573.24it/s]\n",
      " 68%|██████▊   | 10288/15230 [00:18<00:09, 528.61it/s]\n",
      " 68%|██████▊   | 10342/15230 [00:18<00:09, 527.03it/s]\n",
      " 68%|██████▊   | 10402/15230 [00:18<00:08, 545.08it/s]\n",
      " 69%|██████▊   | 10465/15230 [00:18<00:08, 566.91it/s]\n",
      " 69%|██████▉   | 10531/15230 [00:18<00:07, 591.25it/s]\n",
      " 70%|██████▉   | 10591/15230 [00:18<00:08, 571.29it/s]\n",
      " 70%|██████▉   | 10649/15230 [00:19<00:08, 555.51it/s]\n",
      " 70%|███████   | 10710/15230 [00:19<00:07, 565.70it/s]\n",
      " 71%|███████   | 10767/15230 [00:19<00:07, 560.01it/s]\n",
      " 71%|███████   | 10825/15230 [00:19<00:07, 563.67it/s]\n",
      " 71%|███████▏  | 10882/15230 [00:19<00:08, 530.48it/s]\n",
      " 72%|███████▏  | 10936/15230 [00:19<00:08, 532.63it/s]\n",
      " 72%|███████▏  | 10994/15230 [00:19<00:07, 545.62it/s]\n",
      " 73%|███████▎  | 11055/15230 [00:19<00:07, 557.27it/s]\n",
      " 73%|███████▎  | 11114/15230 [00:19<00:07, 564.70it/s]\n",
      " 73%|███████▎  | 11171/15230 [00:20<00:07, 562.54it/s]\n",
      " 74%|███████▎  | 11231/15230 [00:20<00:07, 545.82it/s]\n",
      " 74%|███████▍  | 11296/15230 [00:20<00:06, 571.71it/s]\n",
      " 75%|███████▍  | 11358/15230 [00:20<00:06, 582.70it/s]\n",
      " 75%|███████▌  | 11423/15230 [00:20<00:06, 599.86it/s]\n",
      " 75%|███████▌  | 11484/15230 [00:20<00:06, 592.47it/s]\n",
      " 76%|███████▌  | 11544/15230 [00:20<00:06, 573.97it/s]\n",
      " 76%|███████▌  | 11608/15230 [00:20<00:06, 590.67it/s]\n",
      " 77%|███████▋  | 11676/15230 [00:20<00:05, 615.85it/s]\n",
      " 77%|███████▋  | 11738/15230 [00:20<00:05, 600.77it/s]\n",
      " 77%|███████▋  | 11799/15230 [00:21<00:05, 581.09it/s]\n",
      " 78%|███████▊  | 11861/15230 [00:21<00:05, 589.92it/s]\n",
      " 78%|███████▊  | 11926/15230 [00:21<00:05, 606.65it/s]\n",
      " 79%|███████▊  | 11987/15230 [00:21<00:05, 589.85it/s]\n",
      " 79%|███████▉  | 12047/15230 [00:21<00:05, 554.74it/s]\n",
      " 79%|███████▉  | 12103/15230 [00:21<00:05, 525.24it/s]\n",
      " 80%|███████▉  | 12157/15230 [00:21<00:06, 473.09it/s]\n",
      " 80%|████████  | 12220/15230 [00:21<00:05, 513.49it/s]\n",
      " 81%|████████  | 12288/15230 [00:21<00:05, 556.38it/s]\n",
      " 81%|████████  | 12346/15230 [00:22<00:05, 559.37it/s]\n",
      " 81%|████████▏ | 12412/15230 [00:22<00:04, 585.61it/s]\n",
      " 82%|████████▏ | 12472/15230 [00:22<00:04, 571.20it/s]\n",
      " 82%|████████▏ | 12530/15230 [00:22<00:04, 565.14it/s]\n",
      " 83%|████████▎ | 12587/15230 [00:22<00:04, 566.02it/s]\n",
      " 83%|████████▎ | 12645/15230 [00:22<00:04, 566.26it/s]\n",
      " 83%|████████▎ | 12713/15230 [00:22<00:04, 598.80it/s]\n",
      " 84%|████████▍ | 12778/15230 [00:22<00:04, 608.32it/s]\n",
      " 84%|████████▍ | 12841/15230 [00:22<00:04, 595.82it/s]\n",
      " 85%|████████▍ | 12901/15230 [00:23<00:03, 588.16it/s]\n",
      " 85%|████████▌ | 12961/15230 [00:23<00:03, 584.27it/s]\n",
      " 85%|████████▌ | 13020/15230 [00:23<00:03, 554.02it/s]\n",
      " 86%|████████▌ | 13085/15230 [00:23<00:03, 575.67it/s]\n",
      " 86%|████████▋ | 13148/15230 [00:23<00:03, 590.66it/s]\n",
      " 87%|████████▋ | 13215/15230 [00:23<00:03, 613.38it/s]\n",
      " 87%|████████▋ | 13277/15230 [00:23<00:03, 584.62it/s]\n",
      " 88%|████████▊ | 13336/15230 [00:23<00:03, 541.11it/s]\n",
      " 88%|████████▊ | 13394/15230 [00:23<00:03, 551.31it/s]\n",
      " 88%|████████▊ | 13455/15230 [00:24<00:03, 567.31it/s]\n",
      " 89%|████████▊ | 13513/15230 [00:24<00:03, 567.25it/s]\n",
      " 89%|████████▉ | 13571/15230 [00:24<00:02, 568.86it/s]\n",
      " 89%|████████▉ | 13629/15230 [00:24<00:02, 552.91it/s]\n",
      " 90%|████████▉ | 13690/15230 [00:24<00:02, 568.88it/s]\n",
      " 90%|█████████ | 13753/15230 [00:24<00:02, 583.57it/s]\n",
      " 91%|█████████ | 13821/15230 [00:24<00:02, 607.48it/s]\n",
      " 91%|█████████ | 13882/15230 [00:24<00:02, 577.40it/s]\n",
      " 92%|█████████▏| 13941/15230 [00:24<00:02, 575.61it/s]\n",
      " 92%|█████████▏| 14015/15230 [00:24<00:01, 622.19it/s]\n",
      " 92%|█████████▏| 14078/15230 [00:25<00:01, 618.52it/s]\n",
      " 93%|█████████▎| 14141/15230 [00:25<00:01, 585.61it/s]\n",
      " 93%|█████████▎| 14202/15230 [00:25<00:01, 591.92it/s]\n",
      " 94%|█████████▎| 14262/15230 [00:25<00:01, 574.02it/s]\n",
      " 94%|█████████▍| 14320/15230 [00:25<00:01, 564.06it/s]\n",
      " 94%|█████████▍| 14384/15230 [00:25<00:01, 583.54it/s]\n",
      " 95%|█████████▍| 14443/15230 [00:25<00:01, 578.20it/s]\n",
      " 95%|█████████▌| 14501/15230 [00:25<00:01, 567.67it/s]\n",
      " 96%|█████████▌| 14559/15230 [00:25<00:01, 570.66it/s]\n",
      " 96%|█████████▌| 14617/15230 [00:26<00:01, 549.54it/s]\n",
      " 96%|█████████▋| 14673/15230 [00:26<00:01, 517.35it/s]\n",
      " 97%|█████████▋| 14738/15230 [00:26<00:00, 553.48it/s]\n",
      " 97%|█████████▋| 14794/15230 [00:26<00:00, 539.60it/s]\n",
      " 98%|█████████▊| 14857/15230 [00:26<00:00, 564.55it/s]\n",
      " 98%|█████████▊| 14914/15230 [00:26<00:00, 551.43it/s]\n",
      " 98%|█████████▊| 14974/15230 [00:26<00:00, 564.74it/s]\n",
      " 99%|█████████▊| 15031/15230 [00:26<00:00, 559.95it/s]\n",
      " 99%|█████████▉| 15101/15230 [00:26<00:00, 600.44it/s]\n",
      "100%|█████████▉| 15162/15230 [00:26<00:00, 592.27it/s]\n",
      "100%|██████████| 15230/15230 [00:27<00:00, 613.66it/s]\n",
      "100%|██████████| 15230/15230 [00:27<00:00, 562.35it/s]\n",
      "WARNING:tensorflow:Found 0 new answers: \n",
      "WARNING:tensorflow:Found 1 with no answers: \n",
      "WARNING:tensorflow:Found 0 with trunc answers: \n"
     ]
    }
   ],
   "source": [
    "!python utils\\convert_ids_to_string.py \"dataset/train_dataset.json\"\n",
    "\n",
    "!python arabert-model\\squad_preprocessing.py \\\n",
    "    --input_file \"dataset/train_dataset.json\" \\\n",
    "    --output_file \"dataset/pre/train_dataset-pre.json\" \\\n",
    "    --model_name=$model_name \\\n",
    "    --filter_tydiqa=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1905 [00:00<?, ?it/s]\n",
      "  4%|▎         | 67/1905 [00:00<00:02, 667.56it/s]\n",
      "  7%|▋         | 134/1905 [00:00<00:02, 591.58it/s]\n",
      " 10%|█         | 196/1905 [00:00<00:02, 597.75it/s]\n",
      " 13%|█▎        | 257/1905 [00:00<00:02, 565.54it/s]\n",
      " 17%|█▋        | 316/1905 [00:00<00:02, 573.09it/s]\n",
      " 20%|█▉        | 374/1905 [00:00<00:02, 551.63it/s]\n",
      " 23%|██▎       | 430/1905 [00:00<00:02, 514.98it/s]\n",
      " 26%|██▌       | 486/1905 [00:00<00:02, 525.99it/s]\n",
      " 28%|██▊       | 540/1905 [00:00<00:02, 522.08it/s]\n",
      " 32%|███▏      | 602/1905 [00:01<00:02, 547.51it/s]\n",
      " 35%|███▍      | 659/1905 [00:01<00:02, 545.64it/s]\n",
      " 38%|███▊      | 715/1905 [00:01<00:02, 549.72it/s]\n",
      " 41%|████      | 785/1905 [00:01<00:01, 588.84it/s]\n",
      " 44%|████▍     | 845/1905 [00:01<00:01, 573.52it/s]\n",
      " 47%|████▋     | 904/1905 [00:01<00:01, 576.15it/s]\n",
      " 51%|█████     | 971/1905 [00:01<00:01, 601.27it/s]\n",
      " 54%|█████▍    | 1032/1905 [00:01<00:01, 563.79it/s]\n",
      " 57%|█████▋    | 1094/1905 [00:01<00:01, 579.12it/s]\n",
      " 61%|██████    | 1160/1905 [00:02<00:01, 601.71it/s]\n",
      " 64%|██████▍   | 1221/1905 [00:02<00:01, 603.67it/s]\n",
      " 67%|██████▋   | 1282/1905 [00:02<00:01, 581.30it/s]\n",
      " 70%|███████   | 1341/1905 [00:02<00:00, 575.14it/s]\n",
      " 73%|███████▎  | 1399/1905 [00:02<00:00, 568.21it/s]\n",
      " 77%|███████▋  | 1463/1905 [00:02<00:00, 587.85it/s]\n",
      " 80%|███████▉  | 1522/1905 [00:02<00:00, 576.43it/s]\n",
      " 83%|████████▎ | 1589/1905 [00:02<00:00, 602.65it/s]\n",
      " 87%|████████▋ | 1650/1905 [00:02<00:00, 511.20it/s]\n",
      " 90%|████████▉ | 1709/1905 [00:03<00:00, 531.70it/s]\n",
      " 93%|█████████▎| 1769/1905 [00:03<00:00, 548.19it/s]\n",
      " 96%|█████████▌| 1826/1905 [00:03<00:00, 547.74it/s]\n",
      "100%|█████████▉| 1900/1905 [00:03<00:00, 599.76it/s]\n",
      "100%|██████████| 1905/1905 [00:03<00:00, 569.22it/s]\n",
      "WARNING:tensorflow:Found 0 new answers: \n",
      "WARNING:tensorflow:Found 0 with no answers: \n",
      "WARNING:tensorflow:Found 0 with trunc answers: \n"
     ]
    }
   ],
   "source": [
    "!python utils\\convert_ids_to_string.py \"dataset/test_dataset.json\"\n",
    "\n",
    "!python arabert-model\\squad_preprocessing.py \\\n",
    "    --input_file \"dataset/test_dataset.json\" \\\n",
    "    --output_file \"dataset/pre/test_dataset-pre.json\" \\\n",
    "    --model_name=$model_name \\\n",
    "    --filter_tydiqa=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aubmindlab/bert-base-arabertv02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1903 [00:00<?, ?it/s]\n",
      "  2%|▏         | 47/1903 [00:00<00:04, 459.28it/s]\n",
      "  5%|▌         | 104/1903 [00:00<00:03, 517.04it/s]\n",
      "  9%|▊         | 164/1903 [00:00<00:03, 553.78it/s]\n",
      " 12%|█▏        | 220/1903 [00:00<00:03, 540.72it/s]\n",
      " 14%|█▍        | 275/1903 [00:00<00:03, 532.16it/s]\n",
      " 18%|█▊        | 335/1903 [00:00<00:02, 542.21it/s]\n",
      " 21%|██        | 393/1903 [00:00<00:02, 548.42it/s]\n",
      " 24%|██▎       | 448/1903 [00:00<00:02, 531.93it/s]\n",
      " 26%|██▋       | 503/1903 [00:00<00:02, 536.79it/s]\n",
      " 30%|██▉       | 564/1903 [00:01<00:02, 556.48it/s]\n",
      " 33%|███▎      | 635/1903 [00:01<00:02, 599.93it/s]\n",
      " 37%|███▋      | 696/1903 [00:01<00:02, 584.99it/s]\n",
      " 40%|███▉      | 756/1903 [00:01<00:01, 588.81it/s]\n",
      " 43%|████▎     | 816/1903 [00:01<00:01, 577.90it/s]\n",
      " 46%|████▌     | 878/1903 [00:01<00:01, 585.28it/s]\n",
      " 50%|████▉     | 942/1903 [00:01<00:01, 599.68it/s]\n",
      " 53%|█████▎    | 1003/1903 [00:01<00:01, 591.69it/s]\n",
      " 56%|█████▌    | 1063/1903 [00:01<00:01, 593.53it/s]\n",
      " 59%|█████▉    | 1124/1903 [00:01<00:01, 597.80it/s]\n",
      " 62%|██████▏   | 1184/1903 [00:02<00:01, 590.89it/s]\n",
      " 66%|██████▌   | 1249/1903 [00:02<00:01, 606.02it/s]\n",
      " 69%|██████▉   | 1310/1903 [00:02<00:01, 577.83it/s]\n",
      " 72%|███████▏  | 1369/1903 [00:02<00:00, 546.14it/s]\n",
      " 75%|███████▍  | 1425/1903 [00:02<00:00, 540.86it/s]\n",
      " 78%|███████▊  | 1480/1903 [00:02<00:00, 502.76it/s]\n",
      " 81%|████████  | 1545/1903 [00:02<00:00, 539.19it/s]\n",
      " 84%|████████▍ | 1605/1903 [00:02<00:00, 552.91it/s]\n",
      " 87%|████████▋ | 1661/1903 [00:02<00:00, 531.90it/s]\n",
      " 90%|█████████ | 1720/1903 [00:03<00:00, 547.60it/s]\n",
      " 93%|█████████▎| 1776/1903 [00:03<00:00, 514.72it/s]\n",
      " 97%|█████████▋| 1844/1903 [00:03<00:00, 559.47it/s]\n",
      "100%|█████████▉| 1901/1903 [00:03<00:00, 560.14it/s]\n",
      "100%|██████████| 1903/1903 [00:03<00:00, 559.25it/s]\n",
      "WARNING:tensorflow:Found 0 new answers: \n",
      "WARNING:tensorflow:Found 0 with no answers: \n",
      "WARNING:tensorflow:Found 0 with trunc answers: \n"
     ]
    }
   ],
   "source": [
    "!python utils\\convert_ids_to_string.py \"dataset/val_dataset.json\"\n",
    "\n",
    "!python arabert-model\\squad_preprocessing.py \\\n",
    "    --input_file \"dataset/val_dataset.json\" \\\n",
    "    --output_file \"dataset/pre/val_dataset-pre.json\" \\\n",
    "    --model_name=$model_name \\\n",
    "    --filter_tydiqa=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Custome dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset custom_arabert_dataset (C:/Users/obada/.cache/huggingface/datasets/custom_arabert_dataset/default/0.0.0/1c4765fdb4f7b70ac38451de04478d89d3c2f004b5e408104b78a4053b78ea56)\n",
      "100%|██████████| 2/2 [00:00<00:00, 70.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import custom_arabert_dataset\n",
    "\n",
    "dataset = datasets.load_dataset(\"utils/custom_arabert_dataset.py\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at C:\\Users\\obada\\.cache\\huggingface\\datasets\\custom_arabert_dataset\\default\\0.0.0\\1c4765fdb4f7b70ac38451de04478d89d3c2f004b5e408104b78a4053b78ea56\\cache-42da03ecf39441d6.arrow\n",
      "c:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/26421 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: start_logits,end_logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 45\u001b[0m\n\u001b[0;32m     24\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     25\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./qa_output\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     do_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     overwrite_output_dir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     39\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     40\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     41\u001b[0m     train_dataset\u001b[39m=\u001b[39mtokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     42\u001b[0m     eval_dataset\u001b[39m=\u001b[39mtokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2642\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2644\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2645\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2648\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2690\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2689\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m outputs:\n\u001b[1;32m-> 2690\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2691\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2692\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(outputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m. For reference, the inputs it received are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(inputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2693\u001b[0m         )\n\u001b[0;32m   2694\u001b[0m     \u001b[39m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   2695\u001b[0m     loss \u001b[39m=\u001b[39m outputs[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: start_logits,end_logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def preprocess_function(example):\n",
    "    encoding = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        max_length=384,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    return {\n",
    "        key: torch.tensor(val) for key, val in encoding.items()\n",
    "    }\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qa_output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    save_steps=4000,\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# %%writefile artydiqa.py\n",
    "\"\"\"TODO(tydiqa): Add a description here.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "# TODO(tydiqa): BibTeX citation\n",
    "_CITATION = \"\"\"\\\n",
    "@article{tydiqa,\n",
    "title   = {TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},\n",
    "author  = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki}\n",
    "year    = {2020},\n",
    "journal = {Transactions of the Association for Computational Linguistics}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# TODO(tydiqa):\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\n",
    "The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\n",
    "expresses -- such that we expect models performing well on this set to generalize across a large number of the languages\n",
    "in the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\n",
    "information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\n",
    "don’t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\n",
    "the use of translation (unlike MLQA and XQuAD).\n",
    "\"\"\"\n",
    "\n",
    "# _URL = \"https://storage.googleapis.com/tydiqa/\"\n",
    "\n",
    "# _PRIMARY_URLS = {\n",
    "#     \"train\": _URL + \"v1.0/tydiqa-v1.0-train.jsonl.gz\",\n",
    "#     \"dev\": _URL + \"v1.0/tydiqa-v1.0-dev.jsonl.gz\",\n",
    "# }\n",
    "# _SECONDARY_URLS = {\n",
    "#     \"train\": _URL + \"v1.1/tydiqa-goldp-v1.1-train.json\",\n",
    "#     \"dev\": _URL + \"v1.1/tydiqa-goldp-v1.1-dev.json\",\n",
    "# }\n",
    "\n",
    "#use this for AraBERTv1 and V2\n",
    "_URL = \"https://storage.googleapis.com/tydiqa/\"\n",
    "_URL2 = \"/content/\"\n",
    "_PRIMARY_URLS = {\n",
    "    \"train\": _URL + \"v1.0/tydiqa-v1.0-train.jsonl.gz\",\n",
    "    \"dev\": _URL + \"v1.0/tydiqa-v1.0-dev.jsonl.gz\",\n",
    "}\n",
    "_SECONDARY_URLS = {\n",
    "    \"train\": _URL2 + \"tydiqa-goldp-v1.1-train-pre.json\",\n",
    "    \"dev\": _URL2 + \"tydiqa-goldp-v1.1-dev-pre.json\",\n",
    "}\n",
    "\n",
    "\n",
    "class TydiqaConfig(datasets.BuilderConfig):\n",
    "\n",
    "    \"\"\" BuilderConfig for Tydiqa\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            **kwargs: keyword arguments forwarded to super.\n",
    "        \"\"\"\n",
    "        super(TydiqaConfig, self).__init__(version=datasets.Version(\"1.0.0\", \"\"), **kwargs)\n",
    "\n",
    "\n",
    "class Tydiqa(datasets.GeneratorBasedBuilder):\n",
    "    \"\"\"TODO(tydiqa): Short description of my dataset.\"\"\"\n",
    "\n",
    "    # TODO(tydiqa): Set up version.\n",
    "    VERSION = datasets.Version(\"0.1.0\")\n",
    "    BUILDER_CONFIGS = [\n",
    "        TydiqaConfig(\n",
    "            name=\"primary_task\",\n",
    "            description=textwrap.dedent(\n",
    "                \"\"\"\\\n",
    "          Passage selection task (SelectP): Given a list of the passages in the article, return either (a) the index of\n",
    "          the passage that answers the question or (b) NULL if no such passage exists.\n",
    "          Minimal answer span task (MinSpan): Given the full text of an article, return one of (a) the start and end\n",
    "          byte indices of the minimal span that completely answers the question; (b) YES or NO if the question requires\n",
    "          a yes/no answer and we can draw a conclusion from the passage; (c) NULL if it is not possible to produce a\n",
    "          minimal answer for this question.\"\"\"\n",
    "            ),\n",
    "        ),\n",
    "        TydiqaConfig(\n",
    "            name=\"secondary_task\",\n",
    "            description=textwrap.dedent(\n",
    "                \"\"\"Gold passage task (GoldP): Given a passage that is guaranteed to contain the\n",
    "          answer, predict the single contiguous span of characters that answers the question. This is more similar to\n",
    "          existing reading comprehension datasets (as opposed to the information-seeking task outlined above).\n",
    "          This task is constructed with two goals in mind: (1) more directly comparing with prior work and (2) providing\n",
    "          a simplified way for researchers to use TyDi QA by providing compatibility with existing code for SQuAD 1.1,\n",
    "          XQuAD, and MLQA. Toward these goals, the gold passage task differs from the primary task in several ways:\n",
    "          only the gold answer passage is provided rather than the entire Wikipedia article;\n",
    "          unanswerable questions have been discarded, similar to MLQA and XQuAD;\n",
    "          we evaluate with the SQuAD 1.1 metrics like XQuAD; and\n",
    "         Thai and Japanese are removed since the lack of whitespace breaks some tools.\n",
    "          \"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def _info(self):\n",
    "        # TODO(tydiqa): Specifies the datasets.DatasetInfo object\n",
    "        if self.config.name == \"primary_task\":\n",
    "            return datasets.DatasetInfo(\n",
    "                # This is the description that will appear on the datasets page.\n",
    "                description=_DESCRIPTION,\n",
    "                # datasets.features.FeatureConnectors\n",
    "                features=datasets.Features(\n",
    "                    {\n",
    "                        \"passage_answer_candidates\": datasets.features.Sequence(\n",
    "                            {\n",
    "                                \"plaintext_start_byte\": datasets.Value(\"int32\"),\n",
    "                                \"plaintext_end_byte\": datasets.Value(\"int32\"),\n",
    "                            }\n",
    "                        ),\n",
    "                        \"question_text\": datasets.Value(\"string\"),\n",
    "                        \"document_title\": datasets.Value(\"string\"),\n",
    "                        \"language\": datasets.Value(\"string\"),\n",
    "                        \"annotations\": datasets.features.Sequence(\n",
    "                            {\n",
    "                                # 'annotation_id': datasets.Value('variant'),\n",
    "                                \"passage_answer_candidate_index\": datasets.Value(\"int32\"),\n",
    "                                \"minimal_answers_start_byte\": datasets.Value(\"int32\"),\n",
    "                                \"minimal_answers_end_byte\": datasets.Value(\"int32\"),\n",
    "                                \"yes_no_answer\": datasets.Value(\"string\"),\n",
    "                            }\n",
    "                        ),\n",
    "                        \"document_plaintext\": datasets.Value(\"string\"),\n",
    "                        # 'example_id': datasets.Value('variant'),\n",
    "                        \"document_url\": datasets.Value(\"string\")\n",
    "                        # These are the features of your dataset like images, labels ...\n",
    "                    }\n",
    "                ),\n",
    "                # If there's a common (input, target) tuple from the features,\n",
    "                # specify them here. They'll be used if as_supervised=True in\n",
    "                # builder.as_dataset.\n",
    "                supervised_keys=None,\n",
    "                # Homepage of the dataset for documentation\n",
    "                homepage=\"https://github.com/google-research-datasets/tydiqa\",\n",
    "                citation=_CITATION,\n",
    "            )\n",
    "        elif self.config.name == \"secondary_task\":\n",
    "            return datasets.DatasetInfo(\n",
    "                description=_DESCRIPTION,\n",
    "                features=datasets.Features(\n",
    "                    {\n",
    "                        \"id\": datasets.Value(\"string\"),\n",
    "                        \"title\": datasets.Value(\"string\"),\n",
    "                        \"context\": datasets.Value(\"string\"),\n",
    "                        \"question\": datasets.Value(\"string\"),\n",
    "                        \"answers\": datasets.features.Sequence(\n",
    "                            {\n",
    "                                \"text\": datasets.Value(\"string\"),\n",
    "                                \"answer_start\": datasets.Value(\"int32\"),\n",
    "                            }\n",
    "                        ),\n",
    "                    }\n",
    "                ),\n",
    "                # No default supervised_keys (as we have to pass both question\n",
    "                # and context as input).\n",
    "                supervised_keys=None,\n",
    "                homepage=\"https://github.com/google-research-datasets/tydiqa\",\n",
    "                citation=_CITATION,\n",
    "            )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        \"\"\"Returns SplitGenerators.\"\"\"\n",
    "        # TODO(tydiqa): Downloads the data and defines the splits\n",
    "        # dl_manager is a datasets.download.DownloadManager that can be used to\n",
    "        # download and extract URLs\n",
    "        primary_downloaded = dl_manager.download_and_extract(_PRIMARY_URLS)\n",
    "        secondary_downloaded = dl_manager.download_and_extract(_SECONDARY_URLS)\n",
    "        if self.config.name == \"primary_task\":\n",
    "            return [\n",
    "                datasets.SplitGenerator(\n",
    "                    name=datasets.Split.TRAIN,\n",
    "                    # These kwargs will be passed to _generate_examples\n",
    "                    gen_kwargs={\"filepath\": primary_downloaded[\"train\"]},\n",
    "                ),\n",
    "                datasets.SplitGenerator(\n",
    "                    name=datasets.Split.VALIDATION,\n",
    "                    # These kwargs will be passed to _generate_examples\n",
    "                    gen_kwargs={\"filepath\": primary_downloaded[\"dev\"]},\n",
    "                ),\n",
    "            ]\n",
    "        elif self.config.name == \"secondary_task\":\n",
    "            return [\n",
    "                datasets.SplitGenerator(\n",
    "                    name=datasets.Split.TRAIN,\n",
    "                    # These kwargs will be passed to _generate_examples\n",
    "                    gen_kwargs={\"filepath\": secondary_downloaded[\"train\"]},\n",
    "                ),\n",
    "                datasets.SplitGenerator(\n",
    "                    name=datasets.Split.VALIDATION,\n",
    "                    # These kwargs will be passed to _generate_examples\n",
    "                    gen_kwargs={\"filepath\": secondary_downloaded[\"dev\"]},\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "    def _generate_examples(self, filepath):\n",
    "        \"\"\"Yields examples.\"\"\"\n",
    "        # TODO(tydiqa): Yields (key, example) tuples from the dataset\n",
    "        if self.config.name == \"primary_task\":\n",
    "            with open(filepath, encoding=\"utf-8\") as f:\n",
    "                for id_, row in enumerate(f):\n",
    "                    data = json.loads(row)\n",
    "                    passages = data[\"passage_answer_candidates\"]\n",
    "                    end_byte = [passage[\"plaintext_end_byte\"] for passage in passages]\n",
    "                    start_byte = [passage[\"plaintext_start_byte\"] for passage in passages]\n",
    "                    title = data[\"document_title\"]\n",
    "                    lang = data[\"language\"]\n",
    "                    question = data[\"question_text\"]\n",
    "                    annotations = data[\"annotations\"]\n",
    "                    # annot_ids = [annotation[\"annotation_id\"] for annotation in annotations]\n",
    "                    yes_no_answers = [annotation[\"yes_no_answer\"] for annotation in annotations]\n",
    "                    min_answers_end_byte = [\n",
    "                        annotation[\"minimal_answer\"][\"plaintext_end_byte\"] for annotation in annotations\n",
    "                    ]\n",
    "                    min_answers_start_byte = [\n",
    "                        annotation[\"minimal_answer\"][\"plaintext_start_byte\"] for annotation in annotations\n",
    "                    ]\n",
    "                    passage_cand_answers = [\n",
    "                        annotation[\"passage_answer\"][\"candidate_index\"] for annotation in annotations\n",
    "                    ]\n",
    "                    doc = data[\"document_plaintext\"]\n",
    "                    # example_id = data[\"example_id\"]\n",
    "                    url = data[\"document_url\"]\n",
    "                    yield id_, {\n",
    "                        \"passage_answer_candidates\": {\n",
    "                            \"plaintext_start_byte\": start_byte,\n",
    "                            \"plaintext_end_byte\": end_byte,\n",
    "                        },\n",
    "                        \"question_text\": question,\n",
    "                        \"document_title\": title,\n",
    "                        \"language\": lang,\n",
    "                        \"annotations\": {\n",
    "                            # 'annotation_id': annot_ids,\n",
    "                            \"passage_answer_candidate_index\": passage_cand_answers,\n",
    "                            \"minimal_answers_start_byte\": min_answers_start_byte,\n",
    "                            \"minimal_answers_end_byte\": min_answers_end_byte,\n",
    "                            \"yes_no_answer\": yes_no_answers,\n",
    "                        },\n",
    "                        \"document_plaintext\": doc,\n",
    "                        # 'example_id': example_id,\n",
    "                        \"document_url\": url,\n",
    "                    }\n",
    "        elif self.config.name == \"secondary_task\":\n",
    "            with open(filepath, encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                for article in data[\"data\"]:\n",
    "                    title = article.get(\"title\", \"\").strip()\n",
    "                    for paragraph in article[\"paragraphs\"]:\n",
    "                        context = paragraph[\"context\"].strip()\n",
    "                        for qa in paragraph[\"qas\"]:\n",
    "                            question = qa[\"question\"].strip()\n",
    "                            id_ = qa[\"id\"]\n",
    "                            if \"arabic\" not in id_:\n",
    "                              continue\n",
    "                            answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"] if answer[\"answer_start\"] != -1]                            \n",
    "                            answers = [answer[\"text\"].strip() for answer in qa[\"answers\"] if answer[\"answer_start\"] != -1]\n",
    "                            if len(answers) == 0 or len(answer_starts)==0:\n",
    "                              print(\"question skipped\")\n",
    "                              continue\n",
    "                            assert len(answer_starts)==len(answers)\n",
    "                            # Features currently used are \"context\", \"question\", and \"answers\".\n",
    "                            # Others are extracted here for the ease of future expansions.\n",
    "                            yield id_, {\n",
    "                                \"title\": title,\n",
    "                                \"context\": context,\n",
    "                                \"question\": question,\n",
    "                                \"id\": id_,\n",
    "                                \"answers\": {\n",
    "                                    \"answer_start\": answer_starts,\n",
    "                                    \"text\": answers,\n",
    "                                },\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"aubmindlab/araelectra-base-discriminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\New folder\\AraBERT-qa-model\\arabert-model\\run_qa.py\", line 546, in <module>\n",
      "    main()\n",
      "  File \"d:\\New folder\\AraBERT-qa-model\\arabert-model\\run_qa.py\", line 185, in main\n",
      "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
      "  File \"c:\\Users\\obada\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\hf_argparser.py\", line 341, in parse_args_into_dataclasses\n",
      "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
      "ValueError: Some specified arguments are not used by the HfArgumentParser: ['\\\\']\n"
     ]
    }
   ],
   "source": [
    "!python arabert-model\\run_qa.py \\\n",
    "  --model_name_or_path $model_name \\\n",
    "  --dataset_name artydiqa.py \\\n",
    "  --dataset_config_name \"secondary_task\" \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 4 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ./run \\\n",
    "  --n_best_size 20 \\\n",
    "  --evaluation_strategy epoch \\\n",
    "  --save_steps 20160 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --seed 42 \\\n",
    "  --warmup_steps 500 \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
