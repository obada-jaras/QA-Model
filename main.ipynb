{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2zMCN4oF-rs"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw8o_c4sFsi3"
      },
      "source": [
        "# clone repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uj-zAqzFQ2R"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/obada-jaras/QA-Model.git\n",
        "!git clone https://github.com/obada-jaras/Arabic-QA-Datasets.git\n",
        "!git clone https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRBND-2PFcZq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aub-mind/arabert\n",
        "!mkdir arabert-model\n",
        "!mv arabert arabert-model\n",
        "\n",
        "!cp arabert-model/arabert/examples/question-answering/utils_qa.py arabert-model/\n",
        "!cp arabert-model/arabert/examples/question-answering/trainer_qa.py arabert-model/\n",
        "!cp arabert-model/arabert/examples/question-answering/run_qa.py arabert-model/\n",
        "!cp arabert-model/arabert/examples/question-answering/squad_preprocessing.py arabert-model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXXdPCvuGGrB"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76BuAZeYFgd3"
      },
      "outputs": [],
      "source": [
        "!pip install -r QA-Model/requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmqdMhgbLEck"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# combine datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhIhjyRBFipd"
      },
      "outputs": [],
      "source": [
        "!python QA-Model/utils/merge_json_files.py --input \"$(find 'Arabic-QA-Datasets/All Datasets' -name '*.json')\" --output Arabic-QA-Datasets/merged_dataset.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clqvN4aNShwv"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zOkx8BFMxpF"
      },
      "outputs": [],
      "source": [
        "!mkdir Arabic-QA-Datasets/pre\n",
        "\n",
        "model_name=\"aubmindlab/araelectra-base-discriminator\"\n",
        "!python arabert-model/squad_preprocessing.py \\\n",
        "  --input_file \"Arabic-QA-Datasets/merged_dataset.json\" \\\n",
        "  --output_file \"Arabic-QA-Datasets/pre/merged_dataset_pre.json\" \\\n",
        "  --model_name=$model_name \\\n",
        "  --filter_tydiqa=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb1CfzMZTUm1"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojqfrOIWS931"
      },
      "outputs": [],
      "source": [
        "!python QA-Model/utils/data_split.py \\\n",
        "    --input_file \"Arabic-QA-Datasets/pre/merged_dataset_pre.json\" \\\n",
        "    --output_dir \"Arabic-QA-Datasets/pre\" \\\n",
        "    --train_ratio 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND5msUoaUJt_"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# create custome dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PkGvoUiUNHX"
      },
      "outputs": [],
      "source": [
        "!python QA-Model/utils/save_dataset_loader.py \\\n",
        "    --dataset_loader \"QA-Model/utils/dataset_loader.py\" \\\n",
        "    --train_file \"../Arabic-QA-Datasets/pre/train_dataset.json\" \\\n",
        "    --dev_file \"../Arabic-QA-Datasets/pre/dev_dataset.json\" \\\n",
        "    --output_file \"arabert-model/dataset_loader.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdOlB1BcVEuZ"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMNhqvXBU_mh"
      },
      "outputs": [],
      "source": [
        "model_name=\"aubmindlab/araelectra-base-discriminator\"\n",
        "\n",
        "!python arabert-model/run_qa.py \\\n",
        "  --model_name_or_path $model_name \\\n",
        "  --dataset_name arabert-model/dataset_loader.py \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --per_device_train_batch_size 8 \\\n",
        "  --gradient_accumulation_steps 1 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 5 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir ./run \\\n",
        "  --n_best_size 20 \\\n",
        "  --evaluation_strategy epoch \\\n",
        "  --save_steps 40000 \\\n",
        "  --seed 666 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --warmup_steps 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSj-kLh7YXQZ"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# download the fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZp6RiAqYd76"
      },
      "source": [
        "#### download the model directory to the local machine (from colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Iot5gfIVKjT"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Define the directory you want to download\n",
        "source_directory = \"/content/run\"\n",
        "\n",
        "# Create a zip file from the directory\n",
        "zip_file_name = \"model.zip\"\n",
        "shutil.make_archive(zip_file_name.split('.')[0], 'zip', source_directory)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJuInxx3Yktz"
      },
      "source": [
        "#### copy the model directory to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "621QjjcAYc4C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf8iyKJKYm86"
      },
      "outputs": [],
      "source": [
        "!cp -r \"run\" \"/content/drive/MyDrive/fine-tunedAraBERT/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5eNuc4CYpCe"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# use the model and test it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moQ5dK09YvjQ"
      },
      "source": [
        "#### Load the trained model and tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2qfhJ7UYqhB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_name = \"./run\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgfEjENqY4Vo"
      },
      "source": [
        "#### Define a function to perform predictions using the loaded model and tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tTj2YWPYuWh"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def answer_question(question, context):\n",
        "    nlp = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "    result = nlp(question=question, context=context)\n",
        "    return result['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9k5HbXRY6hU"
      },
      "source": [
        "#### Use the function to answer questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyE1J031ZEkO"
      },
      "source": [
        "###### example #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1IMmhRXY9Ej"
      },
      "outputs": [],
      "source": [
        "context = \"خلال قرابة قرن من الزمن، تحولت مدرسة بنات صغيرة في بلدة بيرزيت، إلى الجامعة الفلسطينية الأكثر تأثيرًا في مسيرة التعليم العالي الفلسطيني، وما رافق ذلك من تأثير على تشكيل الوعي والثقافة بمعناها المعرفي ومعناها المقاوم، الذي عُرفت به بيرزيت خلال تاريخها، فشكلت شوكة في حلق الاحتلال، عبر الإصرار على القيام بدورها التنويري، الذي ما زالت تقوم به بثبات، مشكلةً داخل حرمها مجتمعًا فلسطينيًّا متعدد الثقافات، قادرًا على الحوار والتواصل، ورافضًا للاحتلال كوصي على العقول والثقافة، على سبيل التحرر منه.\"\n",
        "\n",
        "question1 = \"ما الذي تحولت إليه مدرسة بنات بيرزيت؟\"\n",
        "answer1 = answer_question(question1, context)\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"ما العامل الرئيسي الذي أثر في تشكيل الوعي والثقافة في بيرزيت؟\"\n",
        "answer2 = answer_question(question2, context)\n",
        "print(answer2)\n",
        "\n",
        "question3 = \"كيف تعاملت جامعة بيرزيت مع الاحتلال؟\"\n",
        "answer3 = answer_question(question3, context)\n",
        "print(answer3)\n",
        "\n",
        "question4 = \"ما هو الدور الذي تقوم به جامعة بيرزيت بثبات؟\"\n",
        "answer4 = answer_question(question4, context)\n",
        "print(answer4)\n",
        "\n",
        "question5 = \"ما هي الخصائص الرئيسية للمجتمع الفلسطيني داخل حرم جامعة بيرزيت؟\"\n",
        "answer5 = answer_question(question5, context)\n",
        "print(answer5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9YcSaAlZKyA"
      },
      "source": [
        "###### example #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6syiTaHZLnv"
      },
      "outputs": [],
      "source": [
        "context = \"في إطار رسالتھا العامة، تولي جامعة بيرزيت عناية خاصة للبحث العلمي وتعتبره من أھم وظائفها وتنظر إليه كسبيل رئيسي لرفع مستواھا العلمي وتمكينھا من المنافسة وخدمة المجتمع الفلسطيني بشكل خاص، والمجتمع العربي بشكل عام، ولزيادة المعرفة الإنسانية. كما ترى الجامعة في البحث العلمي جزءا ھاما من عمل أعضاء ھيئة التدريس فيھا، وتراعي ھذا المبدأ عند تعيين أعضاء ھيئة التدريس وتوزيع أعبائھم ، وتحويل وضعھم الوظيفي من غير منتظم إلى منتظم . كما تسعى الجامعة إلى منح طلبتھا، من كافة المستويات، فرصة الحصول على مھارات البحث العلمي والمشاركة فيه. كما تلتزم جامعة بيرزيت بالسعي لتوفير البيئة الملائمة والإمكانيات اللازمة للنھوض بالبحث العلمي، من حيث توفير الوقت لأعضاء ھيئة التدريس للقيام بالبحث وتوفير الأماكن والأجھزة والخدمات المكتبية والحاسوبية والدعم المالي وأية متطلبات أخرى يحتاجھا البحث العلمي.\"\n",
        "\n",
        "question1 = \"ما الغرض الرئيسي لتولي جامعة بيرزيت عناية خاصة بالبحث العلمي؟\"\n",
        "answer1 = answer_question(question1, context)\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"كيف تعتبر جامعة بيرزيت البحث العلمي جزءاً من عمل أعضاء هيئة التدريس؟\"\n",
        "answer2 = answer_question(question2, context)\n",
        "print(answer2)\n",
        "\n",
        "question3 = \"ما الذي تسعى الجامعة إلى منح طلابها؟\"\n",
        "answer3 = answer_question(question3, context)\n",
        "print(answer3)\n",
        "\n",
        "question4 = \"كيف تلتزم جامعة بيرزيت بتوفير البيئة الملائمة والإمكانيات اللازمة للنهوض بالبحث العلمي؟\"\n",
        "answer4 = answer_question(question4, context)\n",
        "print(answer4)\n",
        "\n",
        "question5 = \"ما هي المتطلبات التي يحتاجها البحث العلمي حسب جامعة بيرزيت؟\"\n",
        "answer5 = answer_question(question5, context)\n",
        "print(answer5)\n",
        "\n",
        "question6 = \"لمن تقدم جامعة بيرزيت خدماتها بشكل خاص؟\"\n",
        "answer6 = answer_question(question6, context)\n",
        "print(answer6)\n",
        "\n",
        "question7 = \"كيف تنظر جامعة بيرزيت إلى البحث العلمي؟\"\n",
        "answer7 = answer_question(question7, context)\n",
        "print(answer7)\n",
        "\n",
        "question8 = \"ماذا تراعي جامعة بيرزيت عند تعيين أعضاء هيئة التدريس؟\"\n",
        "answer8 = answer_question(question8, context)\n",
        "print(answer8)\n",
        "\n",
        "question9 = \"ما الهدف من تحويل وضع أعضاء هيئة التدريس من غير منتظم إلى منتظم؟\"\n",
        "answer9 = answer_question(question9, context)\n",
        "print(answer9)\n",
        "\n",
        "question10 = \"ما هي المستويات التي تشملها جامعة بيرزيت في منح طلابها مهارات البحث العلمي؟\"\n",
        "answer10 = answer_question(question10, context)\n",
        "print(answer10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbhhHPE6ZNcQ"
      },
      "source": [
        "###### example #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9WYYYwSZP-S"
      },
      "outputs": [],
      "source": [
        "context = \"كان الشاعر نزار قباني شاعرًا سوريًا معروفًا. وُلِد في دمشق في الثالث من مارس 1923 وتوفي في لندن في 30 أبريل 1998.\"\n",
        "\n",
        "question1 = \"متى ولد نزار قباني؟\"\n",
        "answer1 = answer_question(question1, context)\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"في أي مدينة وُلد نزار قباني؟\"\n",
        "answer2 = answer_question(question2, context)\n",
        "print(answer2)\n",
        "\n",
        "question3 = \"متى توفي نزار قباني؟\"\n",
        "answer3 = answer_question(question3, context)\n",
        "print(answer3)\n",
        "\n",
        "question4 = \"في أي مدينة توفي نزار قباني؟\"\n",
        "answer4 = answer_question(question4, context)\n",
        "print(answer4)\n",
        "\n",
        "question5 = \"ما الجنسية التي ينتمي إليها الشاعر نزار قباني؟\"\n",
        "answer5 = answer_question(question5, context)\n",
        "print(answer5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSImtbwvZQl4"
      },
      "source": [
        "###### example #4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5VqWjHfZR3t"
      },
      "outputs": [],
      "source": [
        "context = \"كان الشاعر نزار قباني شاعرًا سوريًا معروفًا. وُلِد في دمشق في الثالث من مارس 1923 وتوفي في لندن في 30 أبريل 1998.\"\n",
        "\n",
        "question = \"متى ولد صلاح الدين الايوبي؟\"\n",
        "answer = answer_question(question, context)\n",
        "print(answer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
